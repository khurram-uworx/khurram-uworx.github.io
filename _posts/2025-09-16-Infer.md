---
title: "Infer.NET: Bernoulli Distribution and Variable Declaration"
date: 2025-09-16
tags:
- infernet
- bayesian
- probabilistic-modeling

comments: true

---

Infer.NET is a framework for running Bayesian inference in graphical models. It allows you to define probabilistic models and perform inference to make predictions or understand the underlying data distribution.

### Bernoulli Distribution

The Bernoulli distribution is a discrete probability distribution for a random variable that can take on two possible outcomes, typically labeled as 0 and 1. It's often used to model a single trial or experiment where the outcome is binary, such as success/failure, yes/no, or true/false.

#### Example of Using Bernoulli in Infer.NET

In Infer.NET, you can define a Bernoulli variable to represent a binary outcome. Here's a simple example:

```csharp
// Define the probability of success
double probabilityOfSuccess = 0.7;

// Create a Bernoulli variable
Bernoulli bernoulliVariable = new Bernoulli(probabilityOfSuccess);

// Sample from the Bernoulli distribution
bool outcome = bernoulliVariable.Sample();

Console.WriteLine(outcome); // Outputs: True or False
```

In this example, `probabilityOfSuccess` is the parameter of the Bernoulli distribution, representing the probability of the outcome being `true`. The `Sample` method generates a random sample from this distribution.

### Other Options to Declare Variables in Infer.NET

Infer.NET provides several other distributions to declare variables, depending on the nature of the data and the problem you're modeling. Here are a few common ones:

1. **Gaussian (Normal) Distribution**: Used for continuous data that follows a bell curve. It's defined by a mean and variance.

   ```csharp
   double mean = 0.0;
   double variance = 1.0;
   Gaussian gaussianVariable = new Gaussian(mean, variance);
   ```

2. **Discrete Distribution**: Used for categorical data with a finite number of outcomes. It's defined by a set of probabilities for each category.

   ```csharp
   Vector probabilities = Vector.FromArray(new double[] { 0.1, 0.3, 0.6 });
   Discrete discreteVariable = new Discrete(probabilities);
   ```

3. **Gamma Distribution**: Used for continuous data that is always positive and often skewed. It's defined by shape and rate parameters.

   ```csharp
   double shape = 2.0;
   double rate = 1.0;
   Gamma gammaVariable = new Gamma(shape, rate);
   ```

4. **Beta Distribution**: Used for continuous data that is bounded between 0 and 1. It's defined by two shape parameters.

   ```csharp
   double alpha = 2.0;
   double beta = 5.0;
   Beta betaVariable = new Beta(alpha, beta);
   ```

Each of these distributions can be used to model different types of data and relationships in a probabilistic model. The choice of distribution depends on the specific characteristics of the data and the assumptions of

In Infer.NET, while there are several built-in distributions to choose from, you can also create custom distributions if the predefined ones do not meet your needs. This can be done by defining your own probability distribution using custom logic.

### Creating a Custom Distribution

To create a custom distribution in Infer.NET, you typically need to:

1. **Define the Logic**: Implement the logic that describes the probability distribution. This might involve specifying how samples are generated or how the probability density function (PDF) is computed.

2. **Use Factors**: In Infer.NET, factors are used to define the relationship between variables. You can use factors to define custom distributions by specifying how the probability of a variable depends on other variables.

3. **Implement Sampling**: If you need to sample from your custom distribution, you may need to implement a method to generate samples according to your defined logic.

Here's a conceptual example of how you might define a custom distribution using factors:

```csharp
// Define a custom distribution using factors
Variable<bool> customVariable = Variable.Bernoulli(0.5);
Variable<double> customFactor = Variable.GaussianFromMeanAndPrecision(0.0, 1.0);

using (Variable.ForEach(customVariable))
{
    using (Variable.If(customVariable))
    {
        customFactor = Variable.GaussianFromMeanAndPrecision(1.0, 1.0);
    }
    using (Variable.IfNot(customVariable))
    {
        customFactor = Variable.GaussianFromMeanAndPrecision(-1.0, 1.0);
    }
}

// Perform inference
InferenceEngine engine = new InferenceEngine();
engine.NumberOfIterations = 100;
engine.Algorithm = new ExpectationPropagation();
engine.ShowProgress = false;

// Obtain the posterior distribution
Gaussian customFactorPosterior = engine.Infer<Gaussian>(customFactor);
Console.WriteLine($"Mean: {customFactorPosterior.GetMean()}, Variance: {customFactorPosterior.GetVariance()}");
```

In this example, a custom distribution is created using a combination of a Bernoulli variable and a Gaussian variable. The `customFactor` variable has a different Gaussian distribution depending on the value of the `customVariable`.

### Considerations

- **Complexity**: Creating custom distributions can be complex and requires a good understanding of probability theory and the Infer.NET framework.
- **Efficiency**: Custom distributions may not be as optimized as the built-in ones, so consider the performance implications.
- **Flexibility**: Custom distributions offer flexibility to model specific scenarios that are not covered by standard distributions.

By using factors and custom logic, you can define distributions tailored to your specific needs in Infer.NET.

---

In Infer.NET, you can indeed add observations to your variables, and the framework will update the distribution of the variables based on these observations. This process is part of performing inference, where the model learns from the data to update its beliefs about the parameters.

### Adding Observations

When you add observations to a variable in Infer.NET, you are essentially providing evidence that the framework uses to update the posterior distribution of the variable. This is a fundamental aspect of Bayesian inference, where prior beliefs are updated with observed data to form posterior beliefs.

### Example with Bernoulli Distribution

Let's walk through an example where we start with a Bernoulli variable with a prior probability of 0.5, add observations, and see how the distribution updates.

```csharp
// Define the prior probability
double priorProbability = 0.5;

// Create a Bernoulli variable with the prior probability
Variable<bool> bernoulliVariable = Variable.Bernoulli(priorProbability);

// Add observations
bool[] observations = { true, false, true, true, false, true, true, true, false, true };
bernoulliVariable.ObservedValue = observations;

// Perform inference to update the distribution
InferenceEngine engine = new InferenceEngine();
engine.NumberOfIterations = 100;
engine.Algorithm = new ExpectationPropagation();
engine.ShowProgress = false;

// Obtain the posterior distribution
Bernoulli posteriorDistribution = engine.Infer<Bernoulli>(bernoulliVariable);
Console.WriteLine($"Posterior Probability: {posteriorDistribution.GetProbTrue()}");
```

### Explanation

1. **Prior Distribution**: Initially, the Bernoulli variable is defined with a prior probability of 0.5.

2. **Observations**: Observations are added to the variable. In this case, there are 10 observations with 7 `true` values and 3 `false` values.

3. **Inference**: The inference engine updates the distribution of the Bernoulli variable based on the observations. The posterior probability is computed using Bayesian inference.

4. **Posterior Distribution**: After adding the observations and performing inference, the posterior probability of the Bernoulli variable is updated. In this example, it will be close to 0.7, reflecting the proportion of `true` values in the observations.

### Key Points

- **Updating Distributions**: Adding observations updates the distribution of the variable to reflect the observed data.
- **Bayesian Inference**: The process of updating beliefs based on observations is a core concept in Bayesian inference.
- **Flexibility**: Infer.NET allows you to add observations and perform inference to update distributions for various types of variables, not just Bernoulli.

By adding observations and performing inference, you can update the distributions of your variables to better reflect the underlying data.

In Infer.NET, you can express the joint probability of two events, such as flipping two fair coins and getting heads on both, using algebraic representations of the variables. This involves defining the individual variables and then combining them to express the joint probability.

### Example: Two Fair Coins

Let's walk through an example where we define two Bernoulli variables for two fair coins and express the probability of getting heads on both coins.

```csharp
// Define the probability of getting heads for a fair coin
double probabilityOfHeads = 0.5;

// Create Bernoulli variables for each coin
Variable<bool> coin1 = Variable.Bernoulli(probabilityOfHeads);
Variable<bool> coin2 = Variable.Bernoulli(probabilityOfHeads);

// Define the joint event of both coins being heads
Variable<bool> bothHeads = coin1 & coin2;

// Perform inference to compute the probability of both coins being heads
InferenceEngine engine = new InferenceEngine();
engine.NumberOfIterations = 100;
engine.Algorithm = new ExpectationPropagation();
engine.ShowProgress = false;

// Obtain the posterior distribution for the joint event
Bernoulli bothHeadsPosterior = engine.Infer<Bernoulli>(bothHeads);
Console.WriteLine($"Probability of both coins being heads: {bothHeadsPosterior.GetProbTrue()}");
```

### Explanation

1. **Individual Variables**: Two Bernoulli variables, `coin1` and `coin2`, are defined to represent the outcomes of flipping two fair coins. Each has a probability of 0.5 for heads.

2. **Joint Event**: The joint event of both coins being heads is expressed using the logical AND (`&`) operator. This creates a new Bernoulli variable, `bothHeads`, which is `true` only if both `coin1` and `coin2` are `true`.

3. **Inference**: The inference engine computes the posterior probability of the joint event `bothHeads`. Since the coins are fair and independent, the probability of both being heads is \(0.5 \times 0.5 = 0.25\).

4. **Posterior Distribution**: The posterior distribution for `bothHeads` gives the probability of both coins being heads, which should be 0.25 for fair coins.

### Key Points

- **Algebraic Representation**: You can use logical operators to combine variables and express joint probabilities.
- **Independence**: The example assumes the coins are independent. If they were not, you would need to account for dependencies in your model.
- **Flexibility**: Infer.NET allows you to model complex relationships between variables using algebraic representations.

By using algebraic representations, you can model and compute the probabilities of complex events involving multiple variables in Infer.NET.


### Posterior Distribution

In the context of Bayesian inference, the **posterior distribution** represents the updated belief about the parameters of a model after incorporating observed data. It is a fundamental concept in Bayesian statistics and is derived using Bayes' theorem, which combines prior beliefs with observed data to produce a more informed belief.

#### Key Concepts:

- **Prior Distribution**: This represents your initial beliefs about the parameters before seeing any data. It can be based on previous knowledge, expert opinion, or a non-informative prior if no prior information is available.

- **Likelihood**: This is the probability of observing the data given the parameters. It measures how likely the observed data is under different parameter values.

- **Posterior Distribution**: This is the updated distribution of the parameters after considering the observed data. It is proportional to the product of the prior distribution and the likelihood.

Mathematically, Bayes' theorem can be expressed as:

\[
\text{Posterior} \propto \text{Likelihood} \times \text{Prior}
\]

In the context of the coin-flipping example, the posterior distribution of the Bernoulli variable represents the updated probability of getting heads after observing the outcomes of several coin flips.

### Initializing a Variable Without Prior Belief

In Bayesian inference, it is common to use a prior distribution to represent initial beliefs. However, if you want to initialize a variable without any prior belief and let the observations entirely determine the distribution, you can use a **non-informative prior**.

#### Non-Informative Prior

A non-informative prior is designed to have minimal influence on the posterior distribution, allowing the data to dominate the inference process. For a Bernoulli variable, a common choice for a non-informative prior is a Beta distribution with parameters \(\alpha = 1\) and \(\beta = 1\), which is equivalent to a uniform distribution over the interval [0, 1].

Here's how you might set this up in Infer.NET:

```csharp
// Use a non-informative prior for the Bernoulli variable
Variable<bool> coin = Variable.Bernoulli(Variable.Beta(1.0, 1.0));

// Add observations
bool[] observations = { true, false, true, true, false, true, true, true, false, true };
coin.ObservedValue = observations;

// Perform inference
InferenceEngine engine = new InferenceEngine();
engine.NumberOfIterations = 100;
engine.Algorithm = new ExpectationPropagation();
engine.ShowProgress = false;

// Obtain the posterior distribution
Bernoulli posteriorDistribution = engine.Infer<Bernoulli>(coin);
Console.WriteLine($"Posterior Probability of Heads: {posteriorDistribution.GetProbTrue()}");
```

### Explanation

- **Non-Informative Prior**: The Beta(1, 1) prior is used to represent a lack of prior belief, allowing the observations to drive the inference.

- **Observations**: The observed data updates the posterior distribution, reflecting the proportion of heads in the observations.

- **Posterior Distribution**: The posterior distribution of the Bernoulli variable is updated based on the observed data, providing an estimate of the probability of heads.

By using a non-informative prior, you can initialize a variable without strong prior beliefs and let the observations determine the distribution. This approach is useful when you have little or no prior information about the parameters.

In Infer.NET, operators are used to combine variables and express relationships between them in a probabilistic model. These operators allow you to define complex probabilistic dependencies and perform inference on them. Here are some of the key operators you can use in Infer.NET:

### Logical Operators

1. **AND (`&`)**: Used to represent the joint probability of two events both occurring. For example, `coin1 & coin2` represents the event where both `coin1` and `coin2` are heads.

2. **OR (`|`)**: Used to represent the probability of at least one of two events occurring. For example, `coin1 | coin2` represents the event where at least one of `coin1` or `coin2` is heads.

3. **NOT (`!`)**: Used to represent the complement of an event. For example, `!coin1` represents the event where `coin1` is tails.

### Arithmetic Operators

1. **Addition (`+`)**: Used to add variables together. This is often used with continuous variables, such as Gaussians, to represent the sum of two quantities.

2. **Subtraction (`-`)**: Used to subtract one variable from another. This is also commonly used with continuous variables.

3. **Multiplication (`*`)**: Used to multiply variables together. This can be used with both discrete and continuous variables to represent interactions between them.

4. **Division (`/`)**: Used to divide one variable by another. This is typically used with continuous variables.

### Comparison Operators

1. **Equal (`==`)**: Used to compare two variables for equality. This can be used to define constraints or to check if two variables have the same value.

2. **Not Equal (`!=`)**: Used to compare two variables for inequality. This can be used to define constraints where two variables should not have the same value.

3. **Greater Than (`>`)**: Used to compare if one variable is greater than another. This is often used with continuous variables.

4. **Less Than (`<`)**: Used to compare if one variable is less than another. This is also commonly used with continuous variables.

5. **Greater Than or Equal To (`>=`)**: Used to compare if one variable is greater than or equal to another.

6. **Less Than or Equal To (`<=`)**: Used to compare if one variable is less than or equal to another.

### Conditional Operators

1. **If (`Variable.If`)**: Used to define conditional relationships between variables. For example, you can use `Variable.If` to specify that a variable should take on a certain value only if a condition is met.

2. **IfNot (`Variable.IfNot`)**: Used to define conditional relationships where a variable should take on a certain value if a condition is not met.

### Array and Collection Operators

1. **ForEach (`Variable.ForEach`)**: Used to iterate over a collection of variables and apply an operation to each one. This is useful for defining models with repeated structures, such as time series or arrays of variables.

2. **Array (`Variable.Array`)**: Used to define an array of variables. This is useful for modeling collections of related variables, such as a sequence of observations.

These operators provide a powerful and flexible way to define complex probabilistic models in Infer.NET. By combining variables using these operators, you can express a wide range of probabilistic relationships and perform inference to update your beliefs based on observed data.

---

Let's consider a real-world example where we can use Infer.NET to model a probabilistic scenario using these operators.

### Example: Medical Diagnosis

Suppose we want to model the probability of a patient having a particular disease based on two symptoms. We'll use the following variables:

- **Disease (`D`)**: A Bernoulli variable representing whether the patient has the disease (`true`) or not (`false`).
- **Symptom 1 (`S1`)**: A Bernoulli variable representing whether the patient exhibits the first symptom.
- **Symptom 2 (`S2`)**: A Bernoulli variable representing whether the patient exhibits the second symptom.

We'll assume the following:

- The probability of having the disease (`D`) is 0.01 (1%).
- If the patient has the disease, the probability of exhibiting Symptom 1 (`S1`) is 0.9 (90%), and Symptom 2 (`S2`) is 0.8 (80%).
- If the patient does not have the disease, the probability of exhibiting Symptom 1 (`S1`) is 0.1 (10%), and Symptom 2 (`S2`) is 0.2 (20%).

We want to compute the probability of the patient having the disease given that they exhibit both symptoms.

### Modeling with Infer.NET

```csharp
// Define the prior probability of having the disease
double priorProbabilityDisease = 0.01;
Variable<bool> disease = Variable.Bernoulli(priorProbabilityDisease);

// Define the conditional probabilities of symptoms given the disease status
Variable<bool> symptom1 = Variable.New<bool>();
Variable<bool> symptom2 = Variable.New<bool>();

using (Variable.If(disease))
{
    symptom1.SetTo(Variable.Bernoulli(0.9));
    symptom2.SetTo(Variable.Bernoulli(0.8));
}

using (Variable.IfNot(disease))
{
    symptom1.SetTo(Variable.Bernoulli(0.1));
    symptom2.SetTo(Variable.Bernoulli(0.2));
}

// Observe that the patient exhibits both symptoms
symptom1.ObservedValue = true;
symptom2.ObservedValue = true;

// Perform inference to compute the posterior probability of the disease
InferenceEngine engine = new InferenceEngine();
engine.NumberOfIterations = 100;
engine.Algorithm = new ExpectationPropagation();
engine.ShowProgress = false;

// Obtain the posterior distribution for the disease
Bernoulli diseasePosterior = engine.Infer<Bernoulli>(disease);
Console.WriteLine($"Posterior Probability of Disease: {diseasePosterior.GetProbTrue()}");
```

### Explanation

1. **Prior Probability**: The prior probability of having the disease is set to 0.01.

2. **Conditional Probabilities**: The probabilities of exhibiting symptoms are conditioned on whether the patient has the disease using `Variable.If` and `Variable.IfNot`.

3. **Observations**: We observe that the patient exhibits both symptoms.

4. **Inference**: The inference engine updates the posterior probability of the disease given the observed symptoms.

5. **Posterior Probability**: The posterior probability of the disease is computed, reflecting the updated belief based on the symptoms.

This example demonstrates how to use logical and conditional operators in Infer.NET to model a real-world scenario involving probabilistic dependencies.

To model a scenario with multiple diseases and symptoms in Infer.NET, you can extend the previous example by defining additional variables and using conditional probabilities to express the relationships between diseases and symptoms. Let's consider a scenario with 3 diseases and 5 symptoms.

### Example: Multiple Diseases and Symptoms

Suppose we have the following:

- **Diseases**: `D1`, `D2`, `D3`
- **Symptoms**: `S1`, `S2`, `S3`, `S4`, `S5`

Each disease has a unique set of probabilities for exhibiting each symptom. We'll assume the following prior probabilities and conditional probabilities for simplicity:

- Prior probabilities of diseases: `P(D1) = 0.01`, `P(D2) = 0.02`, `P(D3) = 0.03`
- Conditional probabilities of symptoms given each disease (e.g., `P(S1|D1)`, `P(S2|D1)`, etc.)

### Modeling with Infer.NET

```csharp
// Define the prior probabilities of diseases
double priorD1 = 0.01;
double priorD2 = 0.02;
double priorD3 = 0.03;

Variable<bool> disease1 = Variable.Bernoulli(priorD1);
Variable<bool> disease2 = Variable.Bernoulli(priorD2);
Variable<bool> disease3 = Variable.Bernoulli(priorD3);

// Define the symptoms
Variable<bool> symptom1 = Variable.New<bool>();
Variable<bool> symptom2 = Variable.New<bool>();
Variable<bool> symptom3 = Variable.New<bool>();
Variable<bool> symptom4 = Variable.New<bool>();
Variable<bool> symptom5 = Variable.New<bool>();

// Define the conditional probabilities of symptoms given each disease
using (Variable.If(disease1))
{
    symptom1.SetTo(Variable.Bernoulli(0.9));
    symptom2.SetTo(Variable.Bernoulli(0.8));
    symptom3.SetTo(Variable.Bernoulli(0.7));
    symptom4.SetTo(Variable.Bernoulli(0.6));
    symptom5.SetTo(Variable.Bernoulli(0.5));
}

using (Variable.If(disease2))
{
    symptom1.SetTo(Variable.Bernoulli(0.4));
    symptom2.SetTo(Variable.Bernoulli(0.6));
    symptom3.SetTo(Variable.Bernoulli(0.8));
    symptom4.SetTo(Variable.Bernoulli(0.9));
    symptom5.SetTo(Variable.Bernoulli(0.7));
}

using (Variable.If(disease3))
{
    symptom1.SetTo(Variable.Bernoulli(0.5));
    symptom2.SetTo(Variable.Bernoulli(0.4));
    symptom3.SetTo(Variable.Bernoulli(0.3));
    symptom4.SetTo(Variable.Bernoulli(0.2));
    symptom5.SetTo(Variable.Bernoulli(0.1));
}

// Observe the symptoms (example observations)
symptom1.ObservedValue = true;
symptom2.ObservedValue = false;
symptom3.ObservedValue = true;
symptom4.ObservedValue = true;
symptom5.ObservedValue = false;

// Perform inference to compute the posterior probabilities of diseases
InferenceEngine engine = new InferenceEngine();
engine.NumberOfIterations = 100;
engine.Algorithm = new ExpectationPropagation();
engine.ShowProgress = false;

// Obtain the posterior distributions for the diseases
Bernoulli disease1Posterior = engine.Infer<Bernoulli>(disease1);
Bernoulli disease2Posterior = engine.Infer<Bernoulli>(disease2);
Bernoulli disease3Posterior = engine.Infer<Bernoulli>(disease3);

Console.WriteLine($"Posterior Probability of Disease 1: {disease1Posterior.GetProbTrue()}");
Console.WriteLine($"Posterior Probability of Disease 2: {disease2Posterior.GetProbTrue()}");
Console.WriteLine($"Posterior Probability of Disease 3: {disease3Posterior.GetProbTrue()}");
```

### Explanation

1. **Prior Probabilities**: The prior probabilities of the diseases are defined.

2. **Conditional Probabilities**: The conditional probabilities of symptoms given each disease are specified using `Variable.If`.

3. **Observations**: The observed symptoms are set.

4. **Inference**: The inference engine updates the posterior probabilities of the diseases based on the observed symptoms.

5. **Posterior Probabilities**: The posterior probabilities of the diseases are computed, reflecting the updated beliefs based on the symptoms.

This example demonstrates how to model multiple diseases and symptoms using conditional probabilities and logical operators in Infer.NET. You can adjust the conditional probabilities and observations to fit your specific scenario.