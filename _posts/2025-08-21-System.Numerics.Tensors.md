---
title: "System.Numerics.Tensors"
date: 2025-08-21
tags:
- Numerics
- ML
comments: true
---

`System.Numerics.Tensors` is a really nice addition to the .NET ecosystem, and its usefulness goes well beyond NLP.

At its core, the library provides **multi-dimensional arrays with efficient memory layout** and operations that are suitable for high-performance scenarios. That means anywhere youâ€™d normally need a `float[,]` or jagged arrays with math-heavy workloads, `Tensor<T>` can shine.

Here are some areas where it can be applied outside of "intent detection" / NLP:

---

### ðŸ”¬ Scientific Computing & Data Analysis

* **Numerical simulations** (physics, chemistry, computational biology).
* **Signal processing** (FFT pipelines, filtering, feature extraction).
* **Statistical models** (covariance matrices, regression, Bayesian inference).

---

### ðŸ–¼ Computer Vision & Graphics

* Representing **images and videos** as 3D/4D tensors (Height Ã— Width Ã— Channels Ã— Batch).
* Preprocessing data for **image classification or object detection**.
* Efficient transformations (normalization, reshaping, cropping, color space conversions).

---

### ðŸŽµ Audio & Time-Series Processing

* Spectrogram and MFCC calculations for **speech recognition**.
* Financial data analysis (sliding windows, rolling averages, feature engineering).
* IoT sensor data streams.

---

### ðŸ¤– Machine Learning Foundations

* Serving as the data backbone for ML models even before integrating **TorchSharp**, **ONNX Runtime**, or **ML.NET**.
* Implementing **custom neural networks** or traditional ML algorithms from scratch in .NET.
* Creating **differentiable programming experiments** (tensors + autodiff).

---

### âš¡ High-Performance Apps

* GPU-friendly computations (works well as a bridge with native libraries like CUDA or DirectML).
* Real-time analytics (processing batches of events as dense tensors).
* Game development (physics simulations, 3D geometry, AI behavior data).

---

ðŸ‘‰ In short: anywhere youâ€™d normally think of **NumPy in Python**, `System.Numerics.Tensors` can be considered the .NET counterpart for building higher-level libraries and efficient numerical pipelines.

---

Let's create a simple yet impactful enterprise-style example that showcases the power of `System.Numerics.Tensors` beyond the most basic use caseâ€”one that highlights multi-dimensional operations, broadcasting, and performance-friendly design.

---

## Enterprise Scenario: Batch Processing of Financial Metrics

Imagine an enterprise dashboard that ingests multiple data streamsâ€”say, daily revenue, expenses, and transaction countsâ€”across several departments. We want to compute:

* The **profit margin** for each department over a week.
* Then, compute the **average and standard deviation** of those margins across departments.

This scenario nicely demonstrates how `Tensor<T>` enables clear, high-performance, and vectorized computations.

### Key Tensor Features Used

* **Tensors as multi-dimensional arrays**: handle data per department, per metric, per day.
* **Broadcasting & element-wise ops**: compute profit margins across dimensions with ease.
* **Statistical functions**: like `Average()` and `StdDev()` for quick aggregation.
  ([Microsoft Learn][1], [NuGet][2])

### Example C# Code

```csharp
using System;
using System.Numerics.Tensors;

class FinancialDashboard
{
    static void Main()
    {
        // Suppose we have 3 departments and 7 days of data.
        int departments = 3;
        int days = 7;

        // Data flattening: [dept1 day1, dept1 day2, ..., dept3 day7]
        float[] revenues = new float[]
        {
            120, 130, 125, 140, 135, 128, 132,    // Dept 1
            200, 210, 205, 220, 215, 208, 212,    // Dept 2
            150, 155, 152, 160, 158, 153, 157     // Dept 3
        };

        float[] expenses = new float[]
        {
            100, 110, 105, 115, 112, 108, 110,
            180, 190, 185, 195, 192, 188, 189,
            140, 145, 142, 150, 148, 143, 147
        };

        // Create tensors: shape [departments, days]
        var revTensor = Tensor.Create(revenues, new IntPtr[] { departments, days });
        var expTensor = Tensor.Create(expenses, new IntPtr[] { departments, days });

        // Profit margin = (Revenue - Expense) / Revenue
        var profitTensor = revTensor.Subtract(expTensor).Divide(revTensor);

        // Compute average margin per department (over 7 days)
        float[] avgPerDept = new float[departments];
        for (int d = 0; d < departments; d++)
        {
            var daySlice = profitTensor.Slice(new IntPtr[] { d, 0 });
            avgPerDept[d] = TensorPrimitives.Average(daySlice.ToDenseTensor().FlattenToSpan());
        }

        // Compute overall average and standard deviation across departments
        var avgTensor = Tensor.Create(avgPerDept, new IntPtr[] { departments });
        float overallAvg = TensorPrimitives.Average(avgTensor.ToDenseTensor().FlattenToSpan());
        float overallStdDev = TensorPrimitives.StdDev(avgTensor.ToDenseTensor().FlattenToSpan());

        Console.WriteLine($"Avg Profit Margin per Dept: {string.Join(", ", avgPerDept):P2}");
        Console.WriteLine($"Overall Avg: {overallAvg:P2}, StdDev: {overallStdDev:P2}");
    }
}
```

### Why This Works

| Feature               | Benefit                                                                                                    |
| --------------------- | ---------------------------------------------------------------------------------------------------------- |
| `Tensor.Create`       | Easily shapes data arrays into meaningful multi-dimensional context. ([Microsoft Learn][3])                |
| Element-wise ops      | `Subtract`, `Divide` let you compute margin across entire sets at once. ([Microsoft Learn][1], [NuGet][2]) |
| Aggregation functions | `Average`, `StdDev` offer quick analytics-ready metrics. ([Microsoft Learn][4])                            |

---

## Takeaways

* **Readable & maintainable**: Domain logic (profit margin, statistics) is clear and decoupled from data plumbing.
* **Performance-oriented**: Leverages SIMD-accelerated tensor operations under the hood. ([NuGet][2])
* **Scalable**: Easily extends to more dimensionsâ€”e.g., more metrics, more granular time slices, more locations.

---

Would you like to extend this example with:

* **Batch forecasts**, rolling windows, or anomaly detection?
* Integration into an enterprise analytics pipeline (e.g., with real-time data ingestion)?
* Or visualizing the tensor computations through charts?

The moment devs start *thinking in terms of vectors/matrices/tensors*, ML stops being mysterious and becomes just "math + data plumbing."

Letâ€™s take your **financial example** and extend it into a very approachable ML use case:

---

# ðŸš€ ML Use Case: Predict Next Dayâ€™s Revenue Using Linear Regression

### Why this example?

* **Simple math** (no neural nets, no hidden layers) â†’ very approachable for traditional engineers.
* **Direct tie to enterprise setting** â†’ â€œGiven past revenue & expenses, can we forecast tomorrow?â€
* **Tensor-friendly** â†’ all operations are vectorized and can run fast.

---

## Step 1: Training Data

Weâ€™ll model revenue as a **linear function of expenses**:

$$
\text{Revenue} \approx w \cdot \text{Expenses} + b
$$

Where:

* **w** is the weight (slope).
* **b** is the bias (intercept).

---

## Step 2: Training with Gradient Descent

Weâ€™ll use tensors to:

1. Compute predictions.
2. Compute the **mean squared error (MSE)** loss.
3. Update $w$ and $b$ iteratively.

---

## Example C# Code (using `System.Numerics.Tensors`)

```csharp
using System;
using System.Numerics.Tensors;

class LinearRegressionExample
{
    static void Main()
    {
        // Expenses (X) and Revenues (Y) for 7 days (Dept 1 for simplicity)
        float[] expenses = { 100, 110, 105, 115, 112, 108, 110 };
        float[] revenues = { 120, 130, 125, 140, 135, 128, 132 };

        var X = Tensor.Create(expenses, new IntPtr[] { expenses.Length });
        var Y = Tensor.Create(revenues, new IntPtr[] { revenues.Length });

        // Initialize parameters (weight w and bias b)
        float w = 0.5f;
        float b = 0f;

        float learningRate = 0.0005f; // small LR for stability
        int epochs = 500;

        for (int epoch = 0; epoch < epochs; epoch++)
        {
            // Prediction: y_pred = w * X + b
            var yPred = X.Multiply(w).Add(b);

            // Error: y_pred - Y
            var error = yPred.Subtract(Y);

            // Mean Squared Error (loss)
            float loss = TensorPrimitives.Mean(
                error.Multiply(error).ToDenseTensor().FlattenToSpan()
            );

            // Gradients: dL/dw, dL/db
            float gradW = 2 * TensorPrimitives.Mean(
                (error.Multiply(X)).ToDenseTensor().FlattenToSpan()
            );
            float gradB = 2 * TensorPrimitives.Mean(
                error.ToDenseTensor().FlattenToSpan()
            );

            // Update parameters
            w -= learningRate * gradW;
            b -= learningRate * gradB;

            if (epoch % 100 == 0)
                Console.WriteLine($"Epoch {epoch}: Loss={loss:F4}, w={w:F4}, b={b:F4}");
        }

        // Test prediction
        float nextExpense = 120;
        float predictedRevenue = w * nextExpense + b;
        Console.WriteLine($"\nPredicted revenue for expense={nextExpense}: {predictedRevenue:F2}");
    }
}
```

---

## ðŸ”‘ What This Shows

* **Tensors as vectors**: expenses & revenues are just 1D tensors.
* **Element-wise ops**: `.Multiply`, `.Add`, `.Subtract` â†’ look like NumPy/PyTorch.
* **Stats/aggregation**: `TensorPrimitives.Mean` lets us compute loss/gradients efficiently.
* **ML logic is approachable**: a loop with math updates, no scary magic.

---

## ðŸ“Š Possible Extensions

* Scale to **multiple departments** â†’ multi-variable regression.
* Use **sliding windows** â†’ time-series forecasting.
* Swap loss/grad update with more advanced optimizers (SGD, Adam).

---

This example makes the point beautifully: once youâ€™re tensor-minded, ML is **just the next abstraction layer**.

ðŸ”¥ â€” Adding **sliding windows** is exactly the kind of thing that sparks the â€œahaâ€ moment for engineers:

âž¡ï¸ â€œOh, so forecasting is just **feature engineering with past data slices**, and the math is still the same!â€

Letâ€™s extend the **linear regression example** to use **sliding windows** on revenue itself to predict the *next dayâ€™s revenue*.

---

# ðŸ“ˆ Sliding Window Forecasting with Tensors

### Idea

* Instead of just â€œexpense â†’ revenue,â€
* Weâ€™ll use the **past N days of revenue** as features to predict the **next dayâ€™s revenue**.

Example: With a window size of 3, the training set becomes:

| Input (past 3 days) | Label (next day) |
| ------------------- | ---------------- |
| \[120, 130, 125]    | 140              |
| \[130, 125, 140]    | 135              |
| \[125, 140, 135]    | 128              |
| â€¦                   | â€¦                |

This is essentially **time series forecasting** â€” but approachable.

---

## Example C# Code

```csharp
using System;
using System.Numerics.Tensors;

class SlidingWindowForecast
{
    static void Main()
    {
        // Historical revenues (Dept 1)
        float[] revenues = { 120, 130, 125, 140, 135, 128, 132, 138, 142, 145 };

        int windowSize = 3; // how many past days we look at
        int samples = revenues.Length - windowSize;

        // Build training data
        float[] Xdata = new float[samples * windowSize];
        float[] Ydata = new float[samples];

        for (int i = 0; i < samples; i++)
        {
            for (int j = 0; j < windowSize; j++)
            {
                Xdata[i * windowSize + j] = revenues[i + j];
            }
            Ydata[i] = revenues[i + windowSize];
        }

        // Tensors: X is [samples, windowSize], Y is [samples]
        var X = Tensor.Create(Xdata, new IntPtr[] { samples, windowSize });
        var Y = Tensor.Create(Ydata, new IntPtr[] { samples });

        // Parameters: weight vector for window + bias
        var W = Tensor.Create(new float[windowSize], new IntPtr[] { windowSize });
        float b = 0f;

        float learningRate = 0.0001f;
        int epochs = 1000;

        for (int epoch = 0; epoch < epochs; epoch++)
        {
            // Prediction: y_pred = XÂ·W + b  (matrix-vector product)
            var yPred = TensorContract(X, W).Add(b);

            // Error
            var error = yPred.Subtract(Y);

            // Loss (MSE)
            float loss = TensorPrimitives.Mean(
                error.Multiply(error).ToDenseTensor().FlattenToSpan()
            );

            // Gradients
            var gradW = TensorContract(X.Transpose(), error).Multiply(2.0f / samples);
            float gradB = 2 * TensorPrimitives.Mean(error.ToDenseTensor().FlattenToSpan());

            // Update
            for (int j = 0; j < windowSize; j++)
                W[j] -= learningRate * gradW[j];
            b -= learningRate * gradB;

            if (epoch % 200 == 0)
                Console.WriteLine($"Epoch {epoch}: Loss={loss:F4}");
        }

        // Predict next revenue based on last window
        float[] lastWindow = { revenues[^3], revenues[^2], revenues[^1] };
        var input = Tensor.Create(lastWindow, new IntPtr[] { windowSize });
        float predicted = DotProduct(input, W) + b;

        Console.WriteLine($"\nLast window: [{string.Join(", ", lastWindow)}]");
        Console.WriteLine($"Predicted next revenue: {predicted:F2}");
    }

    // Helper: dot product (vector-vector)
    static float DotProduct(Tensor<float> a, Tensor<float> b)
    {
        return TensorPrimitives.Dot(a.ToDenseTensor().FlattenToSpan(),
                                    b.ToDenseTensor().FlattenToSpan());
    }

    // Helper: XÂ·W (matrix-vector multiplication)
    static Tensor<float> TensorContract(Tensor<float> matrix, Tensor<float> vector)
    {
        int rows = (int)matrix.Dimensions[0];
        int cols = (int)matrix.Dimensions[1];
        var result = new DenseTensor<float>(new int[] { rows });

        for (int i = 0; i < rows; i++)
        {
            float sum = 0;
            for (int j = 0; j < cols; j++)
                sum += matrix.GetValue(i, j) * vector.GetValue(j);
            result.SetValue(sum, i);
        }
        return result;
    }
}
```

---

## ðŸ”‘ What This Adds

* **Sliding windows as features** â†’ engineers see how past values become inputs.
* **Matrix-vector math** â†’ feels like real ML (linear regression generalized).
* **Forecasting** â†’ practical enterprise use case (sales, revenue, demand, etc.).

---

ðŸ‘‰ Now engineers start to see:

* *Day-to-day computations â†’ Tensors*
* *Tensors â†’ ML-ready pipelines*
* *ML isnâ€™t magic, just structured math over data slices.*

---

## ðŸš€ Things to Try

ðŸ‘‰ **Extend this to multivariate regression** (e.g., predicting revenue using both *expenses* and *transaction count*) so it feels even closer to a real enterprise case?
ðŸ‘‰ **Visualize this sliding window + predictions** with a chart (so it feels closer to an enterprise dashboard)?



[1]: https://learn.microsoft.com/en-us/dotnet/api/system.numerics.tensors.tensor?view=net-9.0-pp "Tensor Class (System.Numerics.Tensors) - Microsoft Learn"
[2]: https://www.nuget.org/packages/System.Numerics.Tensors "System.Numerics.Tensors 9.0.8 - NuGet"
[3]: https://learn.microsoft.com/en-us/dotnet/api/system.numerics.tensors.tensor.create?view=net-9.0-pp "Tensor.Create Method (System.Numerics.Tensors) | Microsoft Learn"
[4]: https://learn.microsoft.com/en-us/dotnet/api/system.numerics.tensors.tensorprimitives.maxnumber?view=net-9.0-pp "TensorPrimitives.MaxNumber Method (System.Numerics.Tensors)"
